{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a fuction to retrieve the pdf file\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    #for pdf in pdf_docs:\n",
    "    pdf_reader = PyPDFLoader(pdf_docs)\n",
    "    for page in pdf_reader.load():\n",
    "        text += page.page_content\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting pdf document\n",
    "text= get_pdf_text(\"R - into .pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting the document into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to perform the splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A\\nBrief\\nIntroduction\\nto\\nR\\nThe\\njourney\\nof\\nstatistical\\ncomputing\\nand\\ngraphics\\ngets\\ninteresting\\nwhen\\nit\\ncomes\\nto\\nR\\nbut\\nbefore\\nwe\\ndelve\\ninto\\nthe\\nfundamental\\nintroduction\\nto\\nwhat\\nR\\nis,\\nlet\\nthe\\nwords\\nof\\nstatistics,\\nstatistical\\ncomputing,\\nand\\ngraphics\\nnot\\ndeter\\nyou\\nfrom\\nstarting.\\nWe\\nare\\nabout\\nto\\nsimplify\\nthem.\\nLet\\nus\\nstart\\nwith\\ndata.\\nData\\nrefers\\nto\\nsimply\\nraw\\ninformation\\nor\\nrather\\nunprocessed\\ninformation\\nWhat\\nare\\nstatistics?\\nStatistics\\nhighlight\\nmethodologies\\nused\\nin\\nthe\\ncollection,\\norganization,'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = text_splitter.split_text(text)\n",
    "texts[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedd segmented text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": \"cpu\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "docs = retriever.get_relevant_documents(\"What is Statistics?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check similarity search is working\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is Statistics?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query)\n\u001b[0;32m      4\u001b[0m docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "# Check similarity search is working\n",
    "query = \"What is Statistics?\"\n",
    "docs = db.similarity_search(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creating a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Mixtral API\n",
    "llm = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",task=\"text-generation\",model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\"temperature\":0.1,\n",
    "        \"repetition_penalty\": 1.03, \"max_length\":64})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Statistics is a field that deals with methodologies used in the collection, organization, and interpretation of data. It involves analyzing raw information to extract meaningful insights and conclusions.\n"
     ]
    }
   ],
   "source": [
    "# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)\n",
    "import re\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "query = \"What is statistics?\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "chain_response = chain.run(input_documents=docs, question=query)\n",
    "\n",
    "# Use regular expressions to find the answer\n",
    "match = re.search(r'Helpful Answer:(.*)', chain_response)\n",
    "if match:\n",
    "    answer = match.group(1).strip()\n",
    "    print(\"Answer:\", answer)\n",
    "else:\n",
    "    print(\"Answer not found in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback: Data refers to raw or unprocessed information.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Defining a function to automate the process\n",
    "def get_feedback(query):\n",
    "    # Load the QA chain\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    \n",
    "    # Perform similarity search\n",
    "    docs = db.similarity_search(query)\n",
    "    \n",
    "    # Run the QA chain\n",
    "    chain_response = chain.run(input_documents=docs, question=query)\n",
    "    \n",
    "    # Use regular expressions to find the answer\n",
    "    match = re.search(r'Helpful Answer:(.*)', chain_response)\n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "        return answer\n",
    "    else:\n",
    "        return \"Answer not found in the response.\"\n",
    "\n",
    "# Get user input\n",
    "user_query = input(\"Enter your query: \")\n",
    "\n",
    "# Get feedback\n",
    "feedback = get_feedback(user_query)\n",
    "\n",
    "# Print feedback\n",
    "print(\"Feedback:\", feedback)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
